{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1.2 - Iris Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are continuing with using basic classifiers, except this time we are working with a famous external dataset: the Iris Dataset, developed by Fisher. IMPORTANT: At least attempt this sheet before looking at the solutions to this practical, you will get so much more out of this by playing with the data, printing things out and understanding it for yourself. Here we have done some things to set you up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the Iris dataset. We see that the features $X$ are a 4-column matrix with all continuous data as the sepal and petal length and width. The y labels are a number [0, 1, 2] representing the associated species with the measurements. You can look up the finer details, in addition to a full view of the entire dataset here: (https://en.wikipedia.org/wiki/Iris_flower_data_set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(\"First 5 rows of features: {}\".format(X[0:5]))\n",
    "print(\"First 5 rows of labels: {}\".format(y[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the size of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Feature size: {}\".format(X.shape))\n",
    "print(\"Label size: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "Using the iris dataset, use a random number generator to select some row indices to remove from the dataset. You can do this with numpy.randint. Make sure you only select unique indices. Then train the DecisionTree classifier on the training data and test with your removed rows using your classifier's predict() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "In the above example, we generate some random integers to act as the indices which select which rows to use as test samples, leaving the majority as training data for the classifier. This practice is so common in Machine Learning there is an infinity-valued function called 'train_test_split' which takes the $X$ and $y$ and returns X_train, X_test, y_train and y_test with optimised splitting. Implement the iris dataset using the train_test_split function.\n",
    "\n",
    "The package you will need is from sklearn.model_selection.\n",
    "\n",
    "Look up the function from the Ski-Kit Learn documentation and use it to generate your training and testing data. Try with 50/50 split, 75/25 and 90/10 (training/testing, respectively) and see which one has the highest accuracy.\n",
    "\n",
    "You can test which one has the highest accuracy using a quantitative scoring function called 'accuracy_score' which is already given. This can be used by giving it the y_test data and the information returned from your classifiers' predict() method. It will return a percentage, where 100% is perfect prediction with all test samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same dataset, use a different classifier than the Decision Tree. We recommend using\n",
    "the K Nearest Neighbours classifier.\n",
    "\n",
    "The import package you want for this is 'sklearn.neighbors'.\n",
    "\n",
    "Again, check out the documentation for this classifier on the website and implement it; the code is remarkably similar to the previous example. \n",
    "\n",
    "Once you have it working, compare the results to the Decision Tree classifier; is there much of a difference? Which is better? What are the advantages and disadvantages of each of the algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4 - Optional\n",
    "\n",
    "Using what you have learnt from this dataset, apply it to another dataset.\n",
    "\n",
    "Go to http://scikit-learn.org/stable/datasets/ and select the load_digits() dataset as it is also a classification problem. Select the diabetes dataset if you really want a challenge!\n",
    "\n",
    "Like the iris dataset, these sets can also be retrieved through the sklearn.datasets class by one simple function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
