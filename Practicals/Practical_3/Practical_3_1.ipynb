{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sms1n16/ACM2/MachineLearning/ML_Intro/Practical_3\n"
     ]
    }
   ],
   "source": [
    "# Don't touch this! Honesly, it's not worth it and I won't be held responsible for what happens if you do...\n",
    "rootdir = % pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading required files\n",
    "\n",
    "The script below downloads the flower photos, extracts them, downloads the tensorflow training code, and the label image Python script. If any of those already exist in the expected directory then they are not downloaded or extracted as they are alreay present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sms1n16/ACM2/MachineLearning/ML_Intro/Practical_3\n"
     ]
    }
   ],
   "source": [
    "% cd $rootdir\n",
    "import os.path\n",
    "\n",
    "#Retrieving some images - For this example we will this set of images\n",
    "if not os.path.isfile(\"flower_photos.tgz\"):\n",
    "    !wget -P tf_files/ http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "\n",
    "#untar the file\n",
    "if not os.path.isdir(\"tf_files/flower_photos/\"):\n",
    "    print(\"Untarring file... \")\n",
    "    % cd tf_files/\n",
    "    !tar -zxf flower_photos.tgz\n",
    "    % cd $rootdir\n",
    "    print(\"Done!\")\n",
    "    !pwd\n",
    "if not os.path.isdir(\"tensorflow/\"):\n",
    "    ##Retrive the training code which can be found at https://github.com/tensorflow/tensorflow\n",
    "    !git clone https://github.com/tensorflow/tensorflow\n",
    "\n",
    "if not os.path.isfile(\"tf_files/label_image.py\"):\n",
    "    !wget https://goo.gl/tx3dqg -O tf_files/label_image.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Inception\n",
    "\n",
    "The bottlenecks for the flower photos have been prebuilt as they usually take around half an hour to make depending on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sms1n16/ACM2/MachineLearning/ML_Intro/Practical_3\n",
      "Untarring file... \n",
      "/Users/sms1n16/ACM2/MachineLearning/ML_Intro/Practical_3/tf_files\n",
      "/Users/sms1n16/ACM2/MachineLearning/ML_Intro/Practical_3\n",
      "Done!\n",
      "/Users/sms1n16/ACM2/MachineLearning/ML_Intro/Practical_3\n",
      "fatal: destination path 'tensorflow' already exists and is not an empty directory.\n",
      "/Users/sms1n16/ACM2/MachineLearning/ML_Intro/Practical_3\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "Looking for images in 'daisy'\n",
      "Looking for images in 'dandelion'\n",
      "Looking for images in 'roses'\n",
      "Looking for images in 'sunflowers'\n",
      "Looking for images in 'tulips'\n",
      "100 bottleneck files created.\n",
      "200 bottleneck files created.\n",
      "300 bottleneck files created.\n",
      "400 bottleneck files created.\n",
      "500 bottleneck files created.\n",
      "600 bottleneck files created.\n",
      "700 bottleneck files created.\n",
      "800 bottleneck files created.\n",
      "900 bottleneck files created.\n",
      "1000 bottleneck files created.\n",
      "1100 bottleneck files created.\n",
      "1200 bottleneck files created.\n",
      "1300 bottleneck files created.\n",
      "1400 bottleneck files created.\n",
      "1500 bottleneck files created.\n",
      "1600 bottleneck files created.\n",
      "1700 bottleneck files created.\n",
      "1800 bottleneck files created.\n",
      "1900 bottleneck files created.\n",
      "2000 bottleneck files created.\n",
      "2100 bottleneck files created.\n",
      "2200 bottleneck files created.\n",
      "2300 bottleneck files created.\n",
      "2400 bottleneck files created.\n",
      "2500 bottleneck files created.\n",
      "2600 bottleneck files created.\n",
      "2700 bottleneck files created.\n",
      "2800 bottleneck files created.\n",
      "2900 bottleneck files created.\n",
      "3000 bottleneck files created.\n",
      "3100 bottleneck files created.\n",
      "3200 bottleneck files created.\n",
      "3300 bottleneck files created.\n",
      "3400 bottleneck files created.\n",
      "3500 bottleneck files created.\n",
      "3600 bottleneck files created.\n",
      "2017-04-10 19:11:01.534643: Step 0: Train accuracy = 61.0%\n",
      "2017-04-10 19:11:01.534791: Step 0: Cross entropy = 1.514404\n",
      "2017-04-10 19:11:01.670514: Step 0: Validation accuracy = 47.0% (N=100)\n",
      "2017-04-10 19:11:02.648686: Step 10: Train accuracy = 77.0%\n",
      "2017-04-10 19:11:02.648762: Step 10: Cross entropy = 1.160388\n",
      "2017-04-10 19:11:02.744654: Step 10: Validation accuracy = 81.0% (N=100)\n",
      "2017-04-10 19:11:03.740686: Step 20: Train accuracy = 79.0%\n",
      "2017-04-10 19:11:03.740748: Step 20: Cross entropy = 0.940378\n",
      "2017-04-10 19:11:03.844988: Step 20: Validation accuracy = 77.0% (N=100)\n",
      "2017-04-10 19:11:04.916032: Step 30: Train accuracy = 75.0%\n",
      "2017-04-10 19:11:04.916147: Step 30: Cross entropy = 0.928081\n",
      "2017-04-10 19:11:05.015559: Step 30: Validation accuracy = 90.0% (N=100)\n",
      "2017-04-10 19:11:05.987309: Step 40: Train accuracy = 87.0%\n",
      "2017-04-10 19:11:05.987383: Step 40: Cross entropy = 0.703472\n",
      "2017-04-10 19:11:06.095378: Step 40: Validation accuracy = 84.0% (N=100)\n",
      "2017-04-10 19:11:07.205779: Step 50: Train accuracy = 83.0%\n",
      "2017-04-10 19:11:07.205867: Step 50: Cross entropy = 0.751760\n",
      "2017-04-10 19:11:07.315277: Step 50: Validation accuracy = 78.0% (N=100)\n",
      "2017-04-10 19:11:08.347525: Step 60: Train accuracy = 79.0%\n",
      "2017-04-10 19:11:08.347588: Step 60: Cross entropy = 0.747975\n",
      "2017-04-10 19:11:08.457247: Step 60: Validation accuracy = 78.0% (N=100)\n",
      "2017-04-10 19:11:09.427102: Step 70: Train accuracy = 84.0%\n",
      "2017-04-10 19:11:09.427166: Step 70: Cross entropy = 0.646608\n",
      "2017-04-10 19:11:09.529121: Step 70: Validation accuracy = 83.0% (N=100)\n",
      "2017-04-10 19:11:10.493272: Step 80: Train accuracy = 90.0%\n",
      "2017-04-10 19:11:10.493400: Step 80: Cross entropy = 0.588456\n",
      "2017-04-10 19:11:10.644094: Step 80: Validation accuracy = 84.0% (N=100)\n",
      "2017-04-10 19:11:11.604075: Step 90: Train accuracy = 81.0%\n",
      "2017-04-10 19:11:11.604146: Step 90: Cross entropy = 0.604711\n",
      "2017-04-10 19:11:11.712098: Step 90: Validation accuracy = 82.0% (N=100)\n",
      "2017-04-10 19:11:12.661365: Step 100: Train accuracy = 84.0%\n",
      "2017-04-10 19:11:12.661434: Step 100: Cross entropy = 0.532974\n",
      "2017-04-10 19:11:12.771999: Step 100: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:13.724618: Step 110: Train accuracy = 85.0%\n",
      "2017-04-10 19:11:13.724682: Step 110: Cross entropy = 0.542810\n",
      "2017-04-10 19:11:13.823589: Step 110: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:14.790217: Step 120: Train accuracy = 79.0%\n",
      "2017-04-10 19:11:14.790294: Step 120: Cross entropy = 0.642802\n",
      "2017-04-10 19:11:14.886902: Step 120: Validation accuracy = 86.0% (N=100)\n",
      "2017-04-10 19:11:15.894338: Step 130: Train accuracy = 91.0%\n",
      "2017-04-10 19:11:15.894405: Step 130: Cross entropy = 0.442828\n",
      "2017-04-10 19:11:15.999553: Step 130: Validation accuracy = 85.0% (N=100)\n",
      "2017-04-10 19:11:17.162085: Step 140: Train accuracy = 86.0%\n",
      "2017-04-10 19:11:17.162148: Step 140: Cross entropy = 0.575740\n",
      "2017-04-10 19:11:17.275429: Step 140: Validation accuracy = 78.0% (N=100)\n",
      "2017-04-10 19:11:18.223291: Step 150: Train accuracy = 92.0%\n",
      "2017-04-10 19:11:18.223357: Step 150: Cross entropy = 0.441628\n",
      "2017-04-10 19:11:18.325824: Step 150: Validation accuracy = 77.0% (N=100)\n",
      "2017-04-10 19:11:19.299013: Step 160: Train accuracy = 83.0%\n",
      "2017-04-10 19:11:19.299085: Step 160: Cross entropy = 0.526572\n",
      "2017-04-10 19:11:19.412470: Step 160: Validation accuracy = 85.0% (N=100)\n",
      "2017-04-10 19:11:20.459590: Step 170: Train accuracy = 88.0%\n",
      "2017-04-10 19:11:20.459655: Step 170: Cross entropy = 0.472262\n",
      "2017-04-10 19:11:20.563083: Step 170: Validation accuracy = 89.0% (N=100)\n",
      "2017-04-10 19:11:21.732464: Step 180: Train accuracy = 86.0%\n",
      "2017-04-10 19:11:21.732558: Step 180: Cross entropy = 0.447709\n",
      "2017-04-10 19:11:21.873752: Step 180: Validation accuracy = 85.0% (N=100)\n",
      "2017-04-10 19:11:22.956365: Step 190: Train accuracy = 87.0%\n",
      "2017-04-10 19:11:22.956451: Step 190: Cross entropy = 0.443817\n",
      "2017-04-10 19:11:23.116733: Step 190: Validation accuracy = 80.0% (N=100)\n",
      "2017-04-10 19:11:24.394077: Step 200: Train accuracy = 91.0%\n",
      "2017-04-10 19:11:24.394144: Step 200: Cross entropy = 0.431542\n",
      "2017-04-10 19:11:24.513458: Step 200: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:25.549481: Step 210: Train accuracy = 86.0%\n",
      "2017-04-10 19:11:25.549546: Step 210: Cross entropy = 0.484854\n",
      "2017-04-10 19:11:25.649418: Step 210: Validation accuracy = 82.0% (N=100)\n",
      "2017-04-10 19:11:26.888558: Step 220: Train accuracy = 88.0%\n",
      "2017-04-10 19:11:26.888623: Step 220: Cross entropy = 0.483466\n",
      "2017-04-10 19:11:26.987347: Step 220: Validation accuracy = 96.0% (N=100)\n",
      "2017-04-10 19:11:28.074775: Step 230: Train accuracy = 96.0%\n",
      "2017-04-10 19:11:28.074854: Step 230: Cross entropy = 0.369890\n",
      "2017-04-10 19:11:28.223096: Step 230: Validation accuracy = 83.0% (N=100)\n",
      "2017-04-10 19:11:29.343627: Step 240: Train accuracy = 91.0%\n",
      "2017-04-10 19:11:29.343705: Step 240: Cross entropy = 0.422863\n",
      "2017-04-10 19:11:29.450640: Step 240: Validation accuracy = 88.0% (N=100)\n",
      "2017-04-10 19:11:30.625963: Step 250: Train accuracy = 93.0%\n",
      "2017-04-10 19:11:30.626028: Step 250: Cross entropy = 0.414916\n",
      "2017-04-10 19:11:30.738852: Step 250: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:31.828892: Step 260: Train accuracy = 88.0%\n",
      "2017-04-10 19:11:31.828981: Step 260: Cross entropy = 0.449384\n",
      "2017-04-10 19:11:32.019985: Step 260: Validation accuracy = 83.0% (N=100)\n",
      "2017-04-10 19:11:33.172292: Step 270: Train accuracy = 88.0%\n",
      "2017-04-10 19:11:33.172364: Step 270: Cross entropy = 0.414954\n",
      "2017-04-10 19:11:33.265962: Step 270: Validation accuracy = 90.0% (N=100)\n",
      "2017-04-10 19:11:34.320691: Step 280: Train accuracy = 90.0%\n",
      "2017-04-10 19:11:34.320761: Step 280: Cross entropy = 0.362365\n",
      "2017-04-10 19:11:34.428460: Step 280: Validation accuracy = 84.0% (N=100)\n",
      "2017-04-10 19:11:35.420698: Step 290: Train accuracy = 87.0%\n",
      "2017-04-10 19:11:35.420795: Step 290: Cross entropy = 0.438908\n",
      "2017-04-10 19:11:35.568256: Step 290: Validation accuracy = 86.0% (N=100)\n",
      "2017-04-10 19:11:36.726330: Step 300: Train accuracy = 94.0%\n",
      "2017-04-10 19:11:36.726394: Step 300: Cross entropy = 0.354953\n",
      "2017-04-10 19:11:36.825673: Step 300: Validation accuracy = 92.0% (N=100)\n",
      "2017-04-10 19:11:37.814490: Step 310: Train accuracy = 92.0%\n",
      "2017-04-10 19:11:37.814585: Step 310: Cross entropy = 0.364541\n",
      "2017-04-10 19:11:37.968704: Step 310: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:39.119306: Step 320: Train accuracy = 87.0%\n",
      "2017-04-10 19:11:39.119372: Step 320: Cross entropy = 0.417566\n",
      "2017-04-10 19:11:39.219784: Step 320: Validation accuracy = 92.0% (N=100)\n",
      "2017-04-10 19:11:40.276418: Step 330: Train accuracy = 84.0%\n",
      "2017-04-10 19:11:40.276483: Step 330: Cross entropy = 0.445923\n",
      "2017-04-10 19:11:40.420668: Step 330: Validation accuracy = 90.0% (N=100)\n",
      "2017-04-10 19:11:41.351560: Step 340: Train accuracy = 92.0%\n",
      "2017-04-10 19:11:41.351624: Step 340: Cross entropy = 0.322437\n",
      "2017-04-10 19:11:41.451116: Step 340: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:42.541603: Step 350: Train accuracy = 93.0%\n",
      "2017-04-10 19:11:42.541669: Step 350: Cross entropy = 0.401230\n",
      "2017-04-10 19:11:42.685168: Step 350: Validation accuracy = 89.0% (N=100)\n",
      "2017-04-10 19:11:43.720812: Step 360: Train accuracy = 93.0%\n",
      "2017-04-10 19:11:43.720888: Step 360: Cross entropy = 0.303367\n",
      "2017-04-10 19:11:43.821181: Step 360: Validation accuracy = 83.0% (N=100)\n",
      "2017-04-10 19:11:44.803208: Step 370: Train accuracy = 92.0%\n",
      "2017-04-10 19:11:44.803274: Step 370: Cross entropy = 0.302552\n",
      "2017-04-10 19:11:44.911767: Step 370: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:45.927642: Step 380: Train accuracy = 94.0%\n",
      "2017-04-10 19:11:45.927721: Step 380: Cross entropy = 0.316513\n",
      "2017-04-10 19:11:46.028210: Step 380: Validation accuracy = 88.0% (N=100)\n",
      "2017-04-10 19:11:47.282273: Step 390: Train accuracy = 92.0%\n",
      "2017-04-10 19:11:47.282361: Step 390: Cross entropy = 0.341493\n",
      "2017-04-10 19:11:47.401462: Step 390: Validation accuracy = 87.0% (N=100)\n",
      "2017-04-10 19:11:48.395611: Step 400: Train accuracy = 93.0%\n",
      "2017-04-10 19:11:48.395678: Step 400: Cross entropy = 0.312784\n",
      "2017-04-10 19:11:48.503975: Step 400: Validation accuracy = 85.0% (N=100)\n",
      "2017-04-10 19:11:49.570377: Step 410: Train accuracy = 90.0%\n",
      "2017-04-10 19:11:49.570456: Step 410: Cross entropy = 0.354724\n",
      "2017-04-10 19:11:49.667983: Step 410: Validation accuracy = 81.0% (N=100)\n",
      "2017-04-10 19:11:50.626964: Step 420: Train accuracy = 92.0%\n",
      "2017-04-10 19:11:50.627035: Step 420: Cross entropy = 0.333845\n",
      "2017-04-10 19:11:50.727203: Step 420: Validation accuracy = 84.0% (N=100)\n",
      "2017-04-10 19:11:51.947330: Step 430: Train accuracy = 88.0%\n",
      "2017-04-10 19:11:51.947408: Step 430: Cross entropy = 0.353915\n",
      "2017-04-10 19:11:52.056175: Step 430: Validation accuracy = 92.0% (N=100)\n",
      "2017-04-10 19:11:53.026688: Step 440: Train accuracy = 97.0%\n",
      "2017-04-10 19:11:53.026760: Step 440: Cross entropy = 0.265282\n",
      "2017-04-10 19:11:53.120192: Step 440: Validation accuracy = 80.0% (N=100)\n",
      "2017-04-10 19:11:54.267910: Step 450: Train accuracy = 90.0%\n",
      "2017-04-10 19:11:54.267999: Step 450: Cross entropy = 0.354062\n",
      "2017-04-10 19:11:54.404856: Step 450: Validation accuracy = 80.0% (N=100)\n",
      "2017-04-10 19:11:55.491133: Step 460: Train accuracy = 88.0%\n",
      "2017-04-10 19:11:55.491220: Step 460: Cross entropy = 0.450846\n",
      "2017-04-10 19:11:55.599361: Step 460: Validation accuracy = 85.0% (N=100)\n",
      "2017-04-10 19:11:56.738984: Step 470: Train accuracy = 93.0%\n",
      "2017-04-10 19:11:56.739105: Step 470: Cross entropy = 0.295590\n",
      "2017-04-10 19:11:56.851993: Step 470: Validation accuracy = 92.0% (N=100)\n",
      "2017-04-10 19:11:57.943244: Step 480: Train accuracy = 91.0%\n",
      "2017-04-10 19:11:57.943337: Step 480: Cross entropy = 0.375497\n",
      "2017-04-10 19:11:58.052213: Step 480: Validation accuracy = 90.0% (N=100)\n",
      "2017-04-10 19:11:59.137379: Step 490: Train accuracy = 86.0%\n",
      "2017-04-10 19:11:59.137720: Step 490: Cross entropy = 0.421879\n",
      "2017-04-10 19:11:59.247322: Step 490: Validation accuracy = 91.0% (N=100)\n",
      "2017-04-10 19:12:00.248899: Step 499: Train accuracy = 87.0%\n",
      "2017-04-10 19:12:00.249104: Step 499: Cross entropy = 0.384755\n",
      "2017-04-10 19:12:00.366381: Step 499: Validation accuracy = 88.0% (N=100)\n",
      "Final test accuracy = 90.6% (N=362)\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "!python tensorflow/tensorflow/examples/image_retraining/retrain.py \\\n",
    "--bottleneck_dir=tf_files/bottlenecks \\\n",
    "--how_many_training_steps 500 \\\n",
    "--model_dir=tf_files/inception \\\n",
    "--output_graph=tf_files/retrained_graph.pb \\\n",
    "--output_labels=tf_files/retrained_labels.txt \\\n",
    "--image_dir tf_files/flower_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify and Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"tf_files/label_image.py\", line 6, in <module>\r\n",
      "    image_data = tf.gfile.FastGFile(image_path, 'rb').read()\r\n",
      "  File \"/Users/sms1n16/anaconda3/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py\", line 106, in read\r\n",
      "    self._preread_check()\r\n",
      "  File \"/Users/sms1n16/anaconda3/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py\", line 73, in _preread_check\r\n",
      "    compat.as_bytes(self.__name), 1024 * 512, status)\r\n",
      "  File \"/Users/sms1n16/anaconda3/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n",
      "    next(self.gen)\r\n",
      "  File \"/Users/sms1n16/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n",
      "    pywrap_tensorflow.TF_GetCode(status))\r\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: tf_files/test.jpg\r\n"
     ]
    }
   ],
   "source": [
    "# Use the script label_image.py\n",
    "!python tf_files/label_image.py tf_files/test.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
